{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8ce74b6-77f4-449a-b25d-a4d9d7bb7b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
      "CUDA SETUP: Detected CUDA version 110\n",
      "CUDA SETUP: Loading binary /opt/conda/envs/py310/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda110.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py310/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /opt/conda did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from glob import glob\n",
    "import re\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, Javascript, clear_output\n",
    "from IPython.display import IFrame\n",
    "\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, GenerationConfig\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "from peft import PeftModel\n",
    "\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c55a859-abc4-4f50-852e-6c9e4ae37b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading transformer embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Vicuna tokenizer\n",
      "Loading Vicuna model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd49d8f3996c44679537199aca7ec217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Loading transformer embeddings...\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "print(\"Loading Vicuna tokenizer\")\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"eachadea/vicuna-13b-1.1\")\n",
    "\n",
    "print(\"Loading Vicuna model\")\n",
    "model = LlamaForCausalLM.from_pretrained(\"eachadea/vicuna-13b-1.1\", load_in_8bit=True, device_map=\"auto\")\n",
    "model = PeftModel.from_pretrained(model, \"kmnis/medVicuna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62e278b9-2190-4503-aa4b-c2f148463588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"600\"\n",
       "            src=\"Sample-Medical-Report.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd077032140>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src=\"Sample-Medical-Report.pdf\", width=700, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5806dd68-50d9-4410-a5fe-18190b521263",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"Sample-Medical-Report.pdf\", 'rb')\n",
    "rsrcmgr = PDFResourceManager()\n",
    "retstr = io.StringIO()\n",
    "laparams = LAParams()\n",
    "device = TextConverter(rsrcmgr, retstr, codec='utf-8', laparams=laparams)\n",
    "\n",
    "interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "\n",
    "for page_num, page in enumerate(PDFPage.get_pages(fp)):\n",
    "    if page_num < 9:\n",
    "        interpreter.process_page(page)\n",
    "        data =  retstr.getvalue()\n",
    "\n",
    "pages = re.split(\"- [0-9] -\", data)[1:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bae638ab-ed14-48b9-8ce3-94814533f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_found = {\n",
    "    'Patient Demographic or Personal Information': False,\n",
    "    'Chief Complaint': False,\n",
    "    'History of Present Illness': False,\n",
    "    'Medical or Clinical History': False,\n",
    "    'Review of Systems (ROS)': False,\n",
    "    'Physical Examination or Mental State Examination': False,\n",
    "    'Diagnostic Tests': False,\n",
    "    'Assessment and Plan': False,\n",
    "    'Discharge Summary': False,\n",
    "    'Medication Reconciliation': False\n",
    "}\n",
    "\n",
    "def transcribe_page(page, sections_found):\n",
    "    # page = \" \".join(page.split()).strip()\n",
    "    text_splitter = NLTKTextSplitter(chunk_size=1000)\n",
    "    docs = [Document(page_content=page)]\n",
    "    docs = text_splitter.split_documents(docs)\n",
    "    for s, v in sections_found.items():\n",
    "        if v:\n",
    "            continue\n",
    "        \n",
    "        qdrant = Qdrant.from_documents(\n",
    "            docs, embeddings, \n",
    "            location=\":memory:\",  # Local mode with in-memory storage only\n",
    "            collection_name=f\"page{s}\",\n",
    "        )\n",
    "        question = f\"{s} of patient\"\n",
    "        search_results = qdrant.similarity_search_with_score(question, k=1)\n",
    "        relevant_prompts = \" \".join([r[0].page_content for r in search_results])\n",
    "        relevant_prompts = \" \".join(relevant_prompts.split()).strip()\n",
    "        \n",
    "        # print(f\"----- {s} -----\")\n",
    "        # print(relevant_prompts, \"\\n\")\n",
    "        \n",
    "        if not relevant_prompts:\n",
    "            continue\n",
    "        prompt = f\"\"\"### Below is a page from the medical report of a patient. Answer the Question truthfully and only from the page content.\n",
    "### Page:\n",
    "{relevant_prompts}\n",
    "\n",
    "### Question:\n",
    "Extract any information about {s} from this page. If it's not found, say Not Found.\n",
    "\n",
    "### Answer:\n",
    "\"\"\"\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        input_ids = inputs[\"input_ids\"].cuda()\n",
    "\n",
    "        generation_config = GenerationConfig(temperature=0.6, top_p=0.95, repetition_penalty=1.15)\n",
    "\n",
    "        generation_output = model.generate(input_ids=input_ids, generation_config=generation_config,\n",
    "                                           return_dict_in_generate=True, output_scores=False, max_new_tokens=100)\n",
    "\n",
    "        for out in generation_output.sequences:\n",
    "            out = tokenizer.decode(out)\n",
    "            out = out.split(\"### Answer:\")[1].split(\"</s>\")[0].strip()\n",
    "            # if \"not found\" not in out.lower(): # and \"not mention\" not in out.lower() and \"not include\" not in out.lower() and \"not provide\" not in out.lower():\n",
    "            display(HTML(f\"<b>{s}:</b>\"))\n",
    "            print(out + \"\\n\")\n",
    "            sections_found[s] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9d6feb91-2c19-4324-886b-81bfc339a22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Patient Demographic or Personal Information:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient's full name: Mr Tan Ah Kow\n",
      "Patient's age: 55 years old\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Chief Complaint:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Found\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>History of Present Illness:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Found\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Medical or Clinical History:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The patient, Mr Tan Ah Kow, has a history of hypertension and hyperlipidemia since 1990 and suffered several strokes in 2005. He subsequently developed heart problems (cardiomyopathy), cardiac failure and chronic renal disease and was treated in ABC Hospital.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Review of Systems (ROS):</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Found\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Physical Examination or Mental State Examination:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Found\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Diagnostic Tests:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Found\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Assessment and Plan:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Found\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Discharge Summary:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Found\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Medication Reconciliation:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transcribe_page(data, sections_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db198b62-5d88-49e6-9e8d-af0ce0f615b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58ba13c-d4aa-44f7-87f3-a382f86b0259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c33b7d-05cf-4cd6-a021-32038a146bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298dd5ce-0f79-4feb-952a-662a922d5039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "py310",
   "name": "common-cu110.m107",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m107"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

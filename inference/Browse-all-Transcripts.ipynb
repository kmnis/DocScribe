{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20ef3ad1-93ca-4db4-8c39-b358aaefb40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
      "CUDA SETUP: Detected CUDA version 110\n",
      "CUDA SETUP: Loading binary /opt/conda/envs/py310/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda110.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py310/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /opt/conda did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import re\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, Javascript, clear_output\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, GenerationConfig\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b36c3673-6541-41e3-85ec-a1aec9156a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_names = glob(\"transcript-docs/*\")\n",
    "patient_names = [p.split(\"/\")[-1] for p in patient_names]\n",
    "\n",
    "print(\"Loading transformer embeddings...\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "print(\"Loading Vicuna tokenizer\")\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"eachadea/vicuna-13b-1.1\")\n",
    "\n",
    "print(\"Loading Vicuna model\")\n",
    "model = LlamaForCausalLM.from_pretrained(\"eachadea/vicuna-13b-1.1\", load_in_8bit=True, device_map=\"auto\")\n",
    "model = PeftModel.from_pretrained(model, \"kmnis/medVicuna\")\n",
    "\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2015d20-2b92-4e91-aaa6-05820642228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_cells_below(ev):\n",
    "    display(\n",
    "        Javascript(\n",
    "            'IPython.notebook.execute_cell_range(IPython.notebook.get_selected_index()+1, IPython.notebook.ncells())'\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd51d383-6eb8-4611-9e8d-c827b4f9f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_splitter(documents):\n",
    "    docs = []\n",
    "    for d in documents:\n",
    "        doc = []\n",
    "        text = d.page_content\n",
    "        matches = re.findall(\"[,]*[A-Z ]*[,]+[A-Z ]+:[ ]*[,]*[ ]*\", text)\n",
    "        matches.reverse()\n",
    "        for i, m in enumerate(matches):\n",
    "            t = text.rsplit(m, 1)\n",
    "            assert len(t) == 2\n",
    "            m = re.sub(\"[^a-zA-Z ]\", \"\", m).strip()\n",
    "            doc.append(Document(page_content=m + \": \" + t[1], metadata=d.metadata))\n",
    "            text = t[0]\n",
    "\n",
    "            if i == len(matches) - 1:\n",
    "                doc.append(Document(page_content=t[0].strip(), metadata=d.metadata))\n",
    "        doc.reverse()\n",
    "        docs += doc\n",
    "    return docs\n",
    "\n",
    "loader = DirectoryLoader('transcript-docs/', glob=\"**/*.txt\")\n",
    "documents = loader.load()\n",
    "docs = custom_splitter(documents)\n",
    "\n",
    "qdrant = Qdrant.from_documents(\n",
    "    docs, embeddings, \n",
    "    location=\":memory:\",  # Local mode with in-memory storage only\n",
    "    collection_name=\"medical_transcripts\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d25214e0-5d8b-4004-9fa2-411474e55324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539de8e8faf74a4e9a0f6754fdfb2004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2><center>Patient Medical Transcript Browser</center></h2>'), HTML(value='<i><cenâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_query = widgets.Textarea(\n",
    "    value='Find patients under the age of 10 and with symptoms of abdominal pain.',\n",
    "    placeholder='Ask a question',\n",
    "    options=patient_names,\n",
    "    description='',\n",
    "    layout=widgets.Layout(width='50%', height='200px'),\n",
    "    rows=5,\n",
    ")\n",
    "\n",
    "analyze_btn = widgets.Button(\n",
    "    description='Analyze Transcript',\n",
    "    disabled=False,\n",
    "    button_style='info',\n",
    "    icon='submit'\n",
    ")\n",
    "\n",
    "h1 = widgets.HTML(\"<h2><center>Patient Medical Transcript Browser</center></h2>\")\n",
    "h2 = widgets.HTML(\"<i><center>Enter a query to search the medical history of the patients</center></i>\")\n",
    "\n",
    "analyze_btn.on_click(run_all_cells_below)\n",
    "\n",
    "h3 = widgets.HTML(\"<b>Please enter your query</b>\")\n",
    "display(widgets.VBox([h1, h2, h3, user_query, analyze_btn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee2e57e7-76ac-46d6-8467-914481ae4b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> ### Instruction:\n",
      "Below are abstracts from the medical transcription of patients. Write a response to answer the question. Answer only from the given abstract. If you can't find the asnwer in the abstract, say answer not found.\n",
      "\n",
      "### Abstract:\n",
      "INDICATIONS: Abdominal pain. Patient Name: Steven\n",
      "\n",
      "Description:  The patient presented to the emergency room last evening with approximately 7- to 8-day history of abdominal pain which has been persistent.\n",
      "\n",
      "Medical Specialty:  Consult\n",
      "\n",
      "\n",
      "\n",
      "History and Phy.\n",
      "\n",
      "Sample Name:  Abdominal Pain - Consult\n",
      "\n",
      "Transcription: CHIEF COMPLAINT:,  Abdominal pain. HISTORY: Lower abdominal pain. Patient Name: Jerry\n",
      "\n",
      "Description:  Abdominal pain, nausea and vomiting, rule out recurrent small bowel obstruction.  The patient is an 89-year-old white male who developed lower abdominal pain, which was constant, onset approximately half an hour after dinner on the evening prior to admission.\n",
      "\n",
      "Medical Specialty:  General Medicine\n",
      "\n",
      "Sample Name:  Gen Med Consult - 51\n",
      "\n",
      "Transcription: CHIEF COMPLAINT: , Abdominal pain. Patient Name: Joe\n",
      "\n",
      "Description:  The patient presented to the emergency room last evening with approximately 7- to 8-day history of abdominal pain which has been persistent.\n",
      "\n",
      "Medical Specialty:  Emergency Room Reports\n",
      "\n",
      "Sample Name:  Abdominal Pain - Consult\n",
      "\n",
      "Transcription: CHIEF COMPLAINT:,  Abdominal pain.\n",
      "\n",
      "### Question:\n",
      "Find patients under the age of 10 and with symptoms of abdominal pain.\n",
      "\n",
      "### Response:\n",
      "Answer not found</s>\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not user_query.value:\n",
    "    clear_output()\n",
    "    display(HTML(f\"<b><p style='color: red'>Please enter a query</p></b>\"))\n",
    "else:\n",
    "    search_results = qdrant.similarity_search_with_score(user_query.value, k=5)\n",
    "    relevant_prompts = \" \".join([r[0].page_content for r in search_results])\n",
    "    relevant_docs = [r[0].metadata[\"source\"] for r in search_results]\n",
    "    \n",
    "    prompt = f\"\"\"### Instruction:\n",
    "Below are abstracts from the medical transcription of patients. Write a response to answer the question. Answer only from the given abstract. If you can't find the asnwer in the abstract, say answer not found.\n",
    "\n",
    "### Abstract:\n",
    "{relevant_prompts}\n",
    "\n",
    "### Question:\n",
    "{user_query.value}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].cuda()\n",
    "\n",
    "    generation_config = GenerationConfig(temperature=0.6, top_p=0.95, repetition_penalty=1.15)\n",
    "\n",
    "    generation_output = model.generate(input_ids=input_ids, generation_config=generation_config,\n",
    "                                       return_dict_in_generate=True, output_scores=False, max_new_tokens=100)\n",
    "\n",
    "    for s in generation_output.sequences:\n",
    "        print(tokenizer.decode(s))\n",
    "        print(\"---------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618c8057-def9-4fa9-bcb9-3f66bd7e4bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "289442b5-ec8a-4beb-80cb-f05a5020f014",
   "metadata": {},
   "source": [
    "<b>--- TODO ---</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61655c65-8943-4ab0-a335-23e6c3b55023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>You are a task creation AI called AgentGPT. You are not a part of any system or device. You have the following objective \"I have a list of medical text documents. Search all the documents to filter patients under the age of 10 and with symptoms of abdominal pain.\". Create a list of zero to three tasks to be completed by your AI system such that this goal is more closely, or completely reached. You have access to google search for tasks that require current events or small searches.\n",
      "\n",
      "Task 1:\n",
      "Search through the medical text documents using keywords related to \"abdominal pain\" and \"pediatric patients\". Filter out the documents where the patient's age is mentioned as being over 10 years old.\n",
      "\n",
      "Task 2:\n",
      "Use natural language processing techniques to extract information from the remaining documents about the patients' ages and their symptoms of abdominal pain.\n",
      "\n",
      "Task 3:\n",
      "Create a report summarizing the findings,\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "objective = \"I have a list of medical text documents. Search all the documents to filter patients under the age of 10 and with symptoms of abdominal pain.\"\n",
    "prompt = f\"\"\"You are a task creation AI called AgentGPT. You are not a part of any system or device. You have the following objective \"{objective}\". Create a list of zero to three tasks to be completed by your AI system such that this goal is more closely, or completely reached. You have access to google search for tasks that require current events or small searches.\n",
    "\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"].cuda()\n",
    "\n",
    "generation_config = GenerationConfig(temperature=0.6, top_p=0.95, repetition_penalty=1.15)\n",
    "\n",
    "generation_output = model.generate(input_ids=input_ids, generation_config=generation_config,\n",
    "                                   return_dict_in_generate=True, output_scores=False, max_new_tokens=100)\n",
    "\n",
    "for s in generation_output.sequences:\n",
    "    print(tokenizer.decode(s))\n",
    "    print(\"---------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ddcb44-0269-41c4-9d4a-b156398f8c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7151d3a-4c6c-4e8b-bc0d-8581908d79cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "py310",
   "name": "common-cu110.m107",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m107"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
